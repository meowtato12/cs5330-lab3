{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "This notebook processes a dataset of LEGO images and annotations, preparing it for training an object detection model using YOLO. \n",
    "\n",
    "The script:\n",
    "1. Parses XML annotations in PASCAL VOC format\n",
    "2. Filters problematic data (unusual boxes, duplicates, etc.)\n",
    "3. Converts annotations to YOLO format\n",
    "4. Splits data into training, validation, and test sets\n",
    "\n",
    "All LEGO pieces are treated as a single class for object detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import Counter\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "img_dir = 'dataset_20210629145407_top_600/images'\n",
    "ann_dir = 'dataset_20210629145407_top_600/annotations'\n",
    "output_dir = \"dataset_yolo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parsed 14999 valid annotations out of 15000 files\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Parse XML annotations and limit the number for faster processing\n",
    "def parse_annotations(annotation_dir, max_annotations=15000):\n",
    "    \"\"\"\n",
    "    Parse XML annotations, filter nonexistent files, and limit the number of annotations.\n",
    "    Args:\n",
    "        annotation_dir: Directory containing XML annotation files\n",
    "        max_annotations: Maximum number of annotations to parse\n",
    "    Returns: List of parsed annotation dictionaries\n",
    "    \"\"\"\n",
    "    annotations = []\n",
    "    count = 0\n",
    "    \n",
    "    for file in os.listdir(annotation_dir):\n",
    "        count += 1\n",
    "        # limit the number of annotations\n",
    "        if count >= max_annotations:\n",
    "            break\n",
    "        \n",
    "        # confirm the file is an XML file\n",
    "        if not file.endswith('.xml'):\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # parse the XML file\n",
    "            file_path = os.path.join(annotation_dir, file)\n",
    "            tree = ET.parse(file_path)\n",
    "            root = tree.getroot()\n",
    "            \n",
    "            # Skip files with missing required elements\n",
    "            if root.find('filename') is None or root.find('size/width') is None:\n",
    "                continue\n",
    "                \n",
    "            image_data = {\n",
    "                'filename': root.find('filename').text,\n",
    "                'xml_file': file,\n",
    "                'size': {\n",
    "                    'width': int(root.find('size/width').text),\n",
    "                    'height': int(root.find('size/height').text),\n",
    "                },\n",
    "                'objects': []\n",
    "            }\n",
    "            \n",
    "            for obj in root.findall('object'):\n",
    "                # Skip objects with missing required elements\n",
    "                if obj.find('name') is None or obj.find('bndbox') is None:\n",
    "                    continue\n",
    "                    \n",
    "                bbox = obj.find('bndbox')\n",
    "                if (bbox.find('xmin') is None or bbox.find('ymin') is None or\n",
    "                    bbox.find('xmax') is None or bbox.find('ymax') is None):\n",
    "                    continue\n",
    "                \n",
    "                # Get difficult flag if available, default to 0\n",
    "                difficult = 0\n",
    "                if obj.find('difficult') is not None:\n",
    "                    difficult = int(obj.find('difficult').text)\n",
    "                \n",
    "                obj_data = {\n",
    "                    'name': obj.find('name').text,\n",
    "                    'difficult': difficult,\n",
    "                    'bbox': {\n",
    "                        'xmin': int(float(bbox.find('xmin').text)),\n",
    "                        'ymin': int(float(bbox.find('ymin').text)),\n",
    "                        'xmax': int(float(bbox.find('xmax').text)),\n",
    "                        'ymax': int(float(bbox.find('ymax').text)),\n",
    "                    }\n",
    "                }\n",
    "                image_data['objects'].append(obj_data)\n",
    "            \n",
    "            # Only add images with at least one valid object\n",
    "            if image_data['objects']:\n",
    "                annotations.append(image_data)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing {file}: {e}\")\n",
    "    \n",
    "    print(f\"\\nParsed {len(annotations)} valid annotations out of {count} files\")\n",
    "    return annotations\n",
    "\n",
    "# Parse annotations\n",
    "annotations = parse_annotations(ann_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered 4096 annotations with unusual bounding box sizes\n",
      "Remaining annotations: 10903\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Filter problematic annotations\n",
    "# Filter unusual bounding box sizes\n",
    "def check_bounding_box(annotations, min_area=100, max_area=50000, min_aspect_ratio=0.2, max_aspect_ratio=5.0):\n",
    "    \"\"\"\n",
    "    Check bounding box areas and filter unusual sizes, such as too small or too large,\n",
    "    too wide or too narrow.\n",
    "    Args:\n",
    "        annotations: List of parsed annotations\n",
    "        min_area: Minimum bounding box area, default 100 (10x10)\n",
    "        max_area: Maximum bounding box area, default 50000 (200x250)\n",
    "        min_aspect_ratio: Minimum bounding box aspect ratio, default 0.2 (1:5)\n",
    "        max_aspect_ratio: Maximum bounding box aspect ratio, default 5.0 (5:1)\n",
    "    Returns: List of filtered annotations\n",
    "    \"\"\"\n",
    "    annotations_filtered = []\n",
    "    for ann in annotations:\n",
    "        valid = True\n",
    "        for obj in ann['objects']:\n",
    "            bbox = obj['bbox']\n",
    "            width = bbox['xmax'] - bbox['xmin']\n",
    "            height = bbox['ymax'] - bbox['ymin']\n",
    "            area = width * height\n",
    "            aspect_ratio = width / height if height > 0 else 0\n",
    "            \n",
    "            if area < min_area or area > max_area or aspect_ratio < min_aspect_ratio or aspect_ratio > max_aspect_ratio:\n",
    "                valid = False\n",
    "                break\n",
    "        if valid:\n",
    "            annotations_filtered.append(ann)\n",
    "    print(f\"\\nFiltered {len(annotations) - len(annotations_filtered)} annotations with unusual bounding box sizes\")\n",
    "    print(f\"Remaining annotations: {len(annotations_filtered)}\")\n",
    "    return annotations_filtered\n",
    "\n",
    "# Filter annotations\n",
    "annotations = check_bounding_box(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered 0 annotations with duplicate boxes (IoU > 0.9)\n",
      "Remaining annotations: 10903\n"
     ]
    }
   ],
   "source": [
    "# Check intersection over union (IoU) between bounding boxes and filter high IoU\n",
    "def calculate_iou(bbox1, bbox2):\n",
    "    \"\"\"\n",
    "    Calculate intersection over union (IoU) between two bounding boxes.\n",
    "    Args:\n",
    "        bbox1: First bounding box coordinates (xmin, ymin, xmax, ymax)\n",
    "        bbox2: Second bounding box coordinates (xmin, ymin, xmax, ymax)\n",
    "    Returns: IoU value\n",
    "    \"\"\"\n",
    "    x_left = max(bbox1['xmin'], bbox2['xmin'])\n",
    "    y_top = max(bbox1['ymin'], bbox2['ymin'])\n",
    "    x_right = min(bbox1['xmax'], bbox2['xmax'])\n",
    "    y_bottom = min(bbox1['ymax'], bbox2['ymax'])\n",
    "    \n",
    "    intersection = max(0, x_right - x_left) * max(0, y_bottom - y_top)\n",
    "    area1 = (bbox1['xmax'] - bbox1['xmin']) * (bbox1['ymax'] - bbox1['ymin'])\n",
    "    area2 = (bbox2['xmax'] - bbox2['xmin']) * (bbox2['ymax'] - bbox2['ymin'])\n",
    "    union = area1 + area2 - intersection\n",
    "    \n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "def check_iou(annotations, max_iou=0.9):\n",
    "    \"\"\"\n",
    "    Check intersection over union (IoU) between bounding boxes and filter annotations with duplicates.\n",
    "    Args:\n",
    "        annotations: List of parsed annotations\n",
    "        max_iou: Maximum IoU threshold to consider boxes as duplicates, default 0.9\n",
    "    Returns: List of filtered annotations without duplicated bounding boxes\n",
    "    \"\"\"\n",
    "    annotations_filtered = []\n",
    "    duplicate = 0\n",
    "    for ann in annotations:\n",
    "        valid = True\n",
    "        objects = ann['objects']\n",
    "        num_objects = len(objects)\n",
    "        \n",
    "        # Skip IoU if there is only one object\n",
    "        if num_objects < 2:\n",
    "            annotations_filtered.append(ann)\n",
    "            continue\n",
    "        \n",
    "        # Calculate IoU for all pairs of objects\n",
    "        for i in range(num_objects):\n",
    "            for j in range(i + 1, num_objects):\n",
    "                iou = calculate_iou(objects[i]['bbox'], objects[j]['bbox'])\n",
    "                if iou > max_iou:\n",
    "                    duplicate += 1\n",
    "                    valid = False\n",
    "                    break\n",
    "            if not valid:\n",
    "                break\n",
    "        if valid:\n",
    "            annotations_filtered.append(ann)\n",
    "    \n",
    "    print(f\"\\nFiltered {duplicate} annotations with duplicate boxes (IoU > {max_iou})\")\n",
    "    print(f\"Remaining annotations: {len(annotations_filtered)}\")\n",
    "    return annotations_filtered\n",
    "\n",
    "annotations = check_iou(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered 1 annotations with missing image files\n",
      "Remaining annotations: 10902\n"
     ]
    }
   ],
   "source": [
    "# Check image files and filter annotations with missing images\n",
    "def check_image(annotations, img_dir):\n",
    "    \"\"\"\n",
    "    Check if image files exist for each annotation.\n",
    "    Args:\n",
    "        annotations: List of parsed annotations\n",
    "        img_dir: Directory containing image files\n",
    "    Returns: List of filtered annotations with existing image files\n",
    "    \"\"\"\n",
    "    annotations_filtered = []\n",
    "    for ann in annotations:\n",
    "        img = ann['filename']\n",
    "        if os.path.exists(os.path.join(img_dir, img)):\n",
    "            annotations_filtered.append(ann)\n",
    "    print(f\"\\nFiltered {len(annotations) - len(annotations_filtered)} annotations with missing image files\")\n",
    "    print(f\"Remaining annotations: {len(annotations_filtered)}\")\n",
    "    return annotations_filtered\n",
    "\n",
    "\n",
    "annotations = check_image(annotations, img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories\n",
    "def create_directory_structure(base_dir):\n",
    "    \"\"\"\n",
    "    Create the directory structure for the YOLO dataset.\n",
    "    Args:\n",
    "        base_dir: Base directory for the dataset\n",
    "    Returns: Dictionary of directory paths\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create base directory\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    \n",
    "    # Create split directories\n",
    "    dirs = {}\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        # Create main split directory\n",
    "        split_dir = os.path.join(base_dir, split)\n",
    "        os.makedirs(split_dir, exist_ok=True)\n",
    "        \n",
    "        # Create images and labels directories\n",
    "        images_dir = os.path.join(split_dir, 'images')\n",
    "        labels_dir = os.path.join(split_dir, 'labels')\n",
    "        os.makedirs(images_dir, exist_ok=True)\n",
    "        os.makedirs(labels_dir, exist_ok=True)\n",
    "        \n",
    "        # Store directory paths\n",
    "        dirs[f'{split}_dir'] = split_dir\n",
    "        dirs[f'{split}_images_dir'] = images_dir\n",
    "        dirs[f'{split}_labels_dir'] = labels_dir\n",
    "    return dirs\n",
    "\n",
    "dirs = create_directory_structure(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset into train, validation, and test sets...\n",
      "Train set: 7631 annotations\n",
      "Validation set: 1635 annotations\n",
      "Test set: 1636 annotations\n",
      "Complete process splits\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Convert annotations to YOLO format and process splits\n",
    "def normalize_bbox(bbox, img_width, img_height):\n",
    "    \"\"\"\n",
    "    Convert a bounding box to YOLO format.\n",
    "    Args:\n",
    "        bbox: Dictionary with xmin, ymin, xmax, ymax keys\n",
    "        img_width: Width of the image\n",
    "        img_height: Height of the image\n",
    "    Returns: Tuple of (x_center, y_center, width, height) normalized to [0, 1]\n",
    "    \"\"\"\n",
    "    # Calculate center coordinates and dimensions\n",
    "    x_center = (bbox['xmin'] + bbox['xmax']) / 2 / img_width\n",
    "    y_center = (bbox['ymin'] + bbox['ymax']) / 2 / img_height\n",
    "    width = (bbox['xmax'] - bbox['xmin']) / img_width\n",
    "    height = (bbox['ymax'] - bbox['ymin']) / img_height\n",
    "    \n",
    "    # Ensure values are within [0, 1]\n",
    "    x_center = max(0, min(1, x_center))\n",
    "    y_center = max(0, min(1, y_center))\n",
    "    width = max(0, min(1, width))\n",
    "    height = max(0, min(1, height))\n",
    "    \n",
    "    return x_center, y_center, width, height\n",
    "\n",
    "def process_split(split_annotations, images_dir, labels_dir, source_img_dir, class_id=0):\n",
    "    \"\"\"\n",
    "    Process a data split by copying images and creating label files in YOLO format.\n",
    "    \n",
    "    Args:\n",
    "        split_annotations: List of annotations for this split\n",
    "        images_dir: Destination directory for images\n",
    "        labels_dir: Destination directory for labels\n",
    "        source_img_dir: Source directory containing original images\n",
    "        class_id: Class ID for YOLO format (default: 0 for all LEGO pieces)\n",
    "    \"\"\"\n",
    "    \n",
    "    for ann in split_annotations:\n",
    "        # Copy image\n",
    "        src_img_path = os.path.join(source_img_dir, ann['filename'])\n",
    "        dst_img_path = os.path.join(images_dir, ann['filename'])\n",
    "        shutil.copy2(src_img_path, dst_img_path)\n",
    "        \n",
    "        # Create label file\n",
    "        filename = os.path.splitext(ann['filename'])[0]\n",
    "        label_path = os.path.join(labels_dir, f\"{filename}.txt\")\n",
    "        \n",
    "        with open(label_path, 'w') as f:\n",
    "            img_width = ann['size']['width']\n",
    "            img_height = ann['size']['height']\n",
    "            \n",
    "            for obj in ann['objects']:\n",
    "                # Convert to YOLO format\n",
    "                x_center, y_center, width, height = normalize_bbox(obj['bbox'], img_width, img_height)\n",
    "                \n",
    "                # Write YOLO format: class_id x_center y_center width height\n",
    "                f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
    "\n",
    "print(\"Splitting dataset into train, validation, and test sets...\")\n",
    "random.seed(42)\n",
    "random.shuffle(annotations)\n",
    "\n",
    "# Split into train (70%), validation (15%), and test (15%)\n",
    "train_annotations, temp_annotations = train_test_split(annotations, test_size=0.3, random_state=42)\n",
    "val_annotations, test_annotations = train_test_split(temp_annotations, test_size=0.5, random_state=42)\n",
    "\n",
    "splits = {\n",
    "        'train': len(train_annotations),\n",
    "        'val': len(val_annotations),\n",
    "        'test': len(test_annotations)\n",
    "    }\n",
    "\n",
    "print(f\"Train set: {splits['train']} annotations\")\n",
    "print(f\"Validation set: {splits['val']} annotations\")\n",
    "print(f\"Test set: {splits['test']} annotations\")\n",
    "\n",
    "# Process splits\n",
    "process_split(train_annotations, dirs['train_images_dir'], dirs['train_labels_dir'], img_dir)\n",
    "process_split(val_annotations, dirs['val_images_dir'], dirs['val_labels_dir'], img_dir)\n",
    "process_split(test_annotations, dirs['test_images_dir'], dirs['test_labels_dir'], img_dir)\n",
    "print(\"Complete process splits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "YAML configuration saved to dataset_yolo/dataset.yaml\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Create a YAML configuration file for YOLOv8\n",
    "def create_yaml_config(output_dir, splits):\n",
    "    \"\"\"\n",
    "    Create a YAML configuration file for YOLOv8.\n",
    "    Args:\n",
    "        output_dir: Output directory for the dataset\n",
    "        splits: Dictionary containing split statistics\n",
    "    \"\"\"\n",
    "    yaml_content = f\"\"\"\n",
    "path: {os.path.abspath(output_dir)}\n",
    "train: train/images\n",
    "val: val/images\n",
    "test: test/images\n",
    "nc: 1  # number of classes\n",
    "names: ['lego']  # class names\n",
    "\"\"\"\n",
    "    # Save the YAML content to a file\n",
    "    yaml_path = os.path.join(output_dir, 'dataset.yaml')\n",
    "    with open(yaml_path, 'w') as f:\n",
    "        f.write(yaml_content)\n",
    "    \n",
    "    print(f\"\\nYAML configuration saved to {yaml_path}\")\n",
    "\n",
    "# Create YAML configuration file\n",
    "create_yaml_config(output_dir, splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: 7631\n",
      "Train labels: 7631\n",
      "Val images: 1635\n",
      "Val labels: 1635\n",
      "Test images: 1636\n",
      "Test labels: 1636\n",
      "\n",
      "Sample label file (ff0fd59e-da2d-11eb-90ee-3497f683a169.txt):\n",
      "0 0.630000 0.675000 0.143333 0.086667\n",
      "0 0.037500 0.628333 0.075000 0.076667\n",
      "0 0.915833 0.424167 0.168333 0.148333\n",
      "0 0.215833 0.289167 0.108333 0.128333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def verify_dataset(dirs):\n",
    "    \"\"\"\n",
    "    Verify the dataset structure and content.\n",
    "    Args:\n",
    "        dirs: Dictionary of directory paths\n",
    "    \"\"\"\n",
    "    # Count files in each directory\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        images_count = len(os.listdir(dirs[f'{split}_images_dir']))\n",
    "        labels_count = len(os.listdir(dirs[f'{split}_labels_dir']))\n",
    "        \n",
    "        print(f\"{split.capitalize()} images: {images_count}\")\n",
    "        print(f\"{split.capitalize()} labels: {labels_count}\")\n",
    "        \n",
    "        # Ensure counts match\n",
    "        if images_count != labels_count:\n",
    "            print(f\"Warning: Mismatch between {split} images and labels!\")\n",
    "    \n",
    "    # Check a random label file to confirm format\n",
    "    split = random.choice(['train', 'val', 'test'])\n",
    "    label_files = glob.glob(os.path.join(dirs[f'{split}_labels_dir'], '*.txt'))\n",
    "    \n",
    "    if label_files:\n",
    "        sample_label = random.choice(label_files)\n",
    "        print(f\"\\nSample label file ({os.path.basename(sample_label)}):\")\n",
    "        with open(sample_label, 'r') as f:\n",
    "            print(f.read())\n",
    "\n",
    "# Verify the dataset\n",
    "verify_dataset(dirs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3",
   "language": "python",
   "name": "python312"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
